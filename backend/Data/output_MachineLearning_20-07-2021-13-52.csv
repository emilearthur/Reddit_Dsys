extracted_at,name,id,title,score,url,author,subreddit,description,created_at
1626789147.129782,t3_omy345,,[D] Machine Learning - WAYR (What Are You Reading) - Week 117,7,https://www.reddit.com/r/MachineLearning/comments/omy345/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,r/MachineLearning,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|81-90|91-100|101-110|111-120|
|----|-----|-----|-----|-----|-----|-----|-----|-----|------|-------|-------|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)|[Week 81](https://reddit.com/f1f0iq)|[Week 91](https://reddit.com/hlt38o)|[Week 101](https://reddit.com/k81ywb)|[Week 111](https://reddit.com/myg8sm)||||||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)|[Week 82](https://reddit.com/f8fs6z)|[Week 92](https://reddit.com/hu6zq9)|[Week 102](https://reddit.com/kh27nx)|[Week 112](https://reddit.com/n8m6ds)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)|[Week 73](https://reddit.com/dkox1s)|[Week 83](https://reddit.com/ffi41b)|[Week 93](https://reddit.com/iaz892)|[Week 103](https://reddit.com/kpsxtc)|[Week 113](https://reddit.com/njfsc6)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)|[Week 74](https://reddit.com/dr6nca)|[Week 84](https://reddit.com/fn62r1)|[Week 94](https://reddit.com/ijjcep)|[Week 104](https://reddit.com/kzevku)|[Week 114](https://reddit.com/ntu6lq)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)|[Week 75](https://reddit.com/dxshkg)|[Week 85](https://reddit.com/fvk7j6)|[Week 95](https://reddit.com/is5hj9)|[Week 105](https://reddit.com/l9lvgs)|[Week 115](https://reddit.com/o4dph1)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)|[Week 76](https://reddit.com/e4nmyk)|[Week 86](https://reddit.com/g4eavg)|[Week 96](https://reddit.com/j0xr24)|[Week 106](https://reddit.com/ljx92n)|[Week 116](https://reddit.com/odrudt)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)|[Week 77](https://reddit.com/eb4lxk)|[Week 87](https://reddit.com/gcx3uf)|[Week 97](https://reddit.com/j9cbfs)|[Week 107](https://reddit.com/luqbxl)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)|[Week 78](https://reddit.com/ehbfst)|[Week 88](https://reddit.com/glm6sv)|[Week 98](https://reddit.com/jhzz9v)|[Week 108](https://reddit.com/m52u5z)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)|[Week 79](https://reddit.com/entcxy)|[Week 89](https://reddit.com/gu5t0d)|[Week 99](https://reddit.com/jqjgo2)|[Week 109](https://reddit.com/mf8m6u)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)|[Week 80](https://reddit.com/euctyw)|[Week 90](https://reddit.com/hddf7j)|[Week 100](https://reddit.com/jz3evt)|[Week 110](https://reddit.com/moy40m)||

Most upvoted papers two weeks ago:

/u/MrUssek: [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230)

/u/TheSunilVarma: https://arxiv.org/abs/2107.00079

Besides that, there are no rules, have fun.",1626638404.0
1626789147.199074,t3_onxw90,,"[N] Researchers from IBM, MIT and Harvard Announced The Release Of DARPA “Common Sense AI” Dataset Along With Two Machine Learning Models At ICML 2021",74,https://www.reddit.com/r/MachineLearning/comments/onxw90/n_researchers_from_ibm_mit_and_harvard_announced/,techsucker,r/MachineLearning,"Building machines that can make decisions based on common sense is no easy feat. A machine must be able to do more than merely find patterns in data; it also needs a way of interpreting the intentions and beliefs behind people’s choices.

At the 2021 International Conference on Machine Learning (ICML), Researchers from IBM, MIT, and Harvard University have come together to release a [DARPA “Common Sense AI” dataset](https://arxiv.org/pdf/2102.12321.pdf) for benchmarking AI intuition. They are also releasing [two machine learning models](https://arxiv.org/pdf/2102.12321.pdf) that represent different approaches to the problem that relies on testing techniques psychologists use to study infants’ behavior to accelerate the development of AI exhibiting common sense. 

Summary: [https://www.marktechpost.com/2021/07/20/researchers-from-ibm-mit-and-harvard-announced-the-release-of-its-darpa-common-sense-ai-dataset-along-with-two-machine-learning-models-at-icml-2021/](https://www.marktechpost.com/2021/07/20/researchers-from-ibm-mit-and-harvard-announced-the-release-of-its-darpa-common-sense-ai-dataset-along-with-two-machine-learning-models-at-icml-2021/) 

Paper: [https://arxiv.org/pdf/2102.12321.pdf](https://arxiv.org/pdf/2102.12321.pdf)

IBM Blog: https://research.ibm.com/blog/icml-darpa-agent",1626769244.0
1626789147.213802,t3_ontqo0,,"[D] Best methods for imbalanced multi-class classification with high dimensional, sparse predictors",79,https://www.reddit.com/r/MachineLearning/comments/ontqo0/d_best_methods_for_imbalanced_multiclass/,ChazzFingers,r/MachineLearning,"Hi everyone,

Im currently working with a very high dimensional data set of dimensions \~ 84,000 \* 190,000. The response variable is categorical with 9 levels and is quite imbalanced. Further, the predictors are very sparse, i.e. the vast majority of predictors are 0 for any given observation. I'm looking to develop a strong predictive model with this data but am at a bit of a loss as to what models /techniques to use.

Currently I'm using SVD (non-centered to preserve sparse matrix format of predictors) to reduce dimensions of predictors and have been experimenting with OVR logistic regression with/without penalties and random forests on the SVD components. I've heard SVCs can be good for these kinds of problems but my results using OVR SVCs have been disappointing (below zero R accuracy).

Would love to hear any/all suggestions on what models might provide accurate classification on this data.

Thanks very much",1626750871.0
1626789147.232385,t3_onyofp,,[D] What is the method to deal with sparse high dimensional feature columns,6,https://www.reddit.com/r/MachineLearning/comments/onyofp/d_what_is_the_method_to_deal_with_sparse_high/,aviisu,r/MachineLearning,"For more context: I am working on medicine application that take an input as the symptom of patience (headache, nausea, rash on the skin, coughing, etc.) encoded in HPO code form (https://hpo.jax.org/app/) and make a prediction on what disease should the patient be (fever, flu, diabetes, etc.)

My currently design choice is encode the HPO code (symptoms) into one hot vector and use a machine learning algorithm (random forest, for example). The training set could look something like this



Text| HPO1(headache)| HPO2(nausea)| HPO3(coughing)| ...| ...| HPO30000(rash on skin)| labels
---|---|----|----|----|----|----|----
headache, nausea, coughing | 1| 1| 1| ...| ...| 0| flu
headache, coughing | 1 | 0| 1| ...| ...| 0| fever
...| ...| ...| ...| ...| ...| ...| ...
...| ...| ...| ...| ...| ...| ...| ...
100000+ rows| ...| ...| ...| ...| ...| ...| ...

The problem is that with so much features columns (30000+ coumns) and rows(100000+ rows), I'm not sure if using machine learning algorithm like random forest will be good for this option,** especially that most of the columns are 0s and only fews are 1s (for example, the first row is 3 'one' out of 30000 'zero')** I feel like there is a better way to tackle/look at the problem. I feel like using dimensionality reduction (like PCA) will not be good because all columns are important.

I would love to hear what you guys think about this, or suggest the resources to read further. Thank you very much.",1626773321.0
1626789147.245857,t3_ontz4j,,[R] Autonomy 2.0: Why is self-driving always 5 years away?,12,https://arxiv.org/abs/2107.08142,hardmaru,r/MachineLearning,,1626751775.0
1626789147.255588,t3_onmjv3,,[P] Reverse-mode automatic differentiation in Haskell using delimited continuations,38,https://www.reddit.com/r/MachineLearning/comments/onmjv3/p_reversemode_automatic_differentiation_in/,spindly-torque,r/MachineLearning,"A Haskell implementation of the reverse AD framework presented in [1], available as a lightweight and easily extensible library:

[https://hackage.haskell.org/package/ad-delcont](https://hackage.haskell.org/package/ad-delcont) 

Blog post introducing the delimited continuation operators `shift`/`reset` and explaining why this technique is an alternative approach to AD by source transformation, or non-standard evaluation based on ""tape"" or ""graph"" reified programs:

[http://ocramz.github.io/haskell/automatic-differentiation/2021/07/19/ad-delcont.html](http://ocramz.github.io/haskell/automatic-differentiation/2021/07/19/ad-delcont.html) 



References

\[1\] Wang et al, Backpropagation with callbacks: Foundations for Efficient and Expressive Differentiable Programming, [https://proceedings.neurips.cc/paper/2018/hash/34e157766f31db3d2099831d348a7933-Abstract.html](https://proceedings.neurips.cc/paper/2018/hash/34e157766f31db3d2099831d348a7933-Abstract.html)",1626726679.0
1626789147.271352,t3_onpgii,,[D] How does the mind work (as an algorithm) -- join us this Wednesday.,25,https://www.reddit.com/r/MachineLearning/comments/onpgii/d_how_does_the_mind_work_as_an_algorithm_join_us/,Rina-Panigrahy,r/MachineLearning,"What is the right logical architecture that captures the essential capabilities of the mind? Is it logically equivalent to some deep learned system perhaps augmented with some kind of memory or knowledge graph and consists of several deep learned modules that interact with each other?

It would be nice to have a discussion about these questions -- please join the following google-meet link for an informal discussion (there are no planned participants yet and anyone can chime in). We could touch upon basic questions around an architecture for the mind (such as [https://docs.google.com/document/d/1tS-B2BTXixqucUPzLm5o6VnbvTY5EMbxzr\_ox5RF3zQ/edit](https://docs.google.com/document/d/1tS-B2BTXixqucUPzLm5o6VnbvTY5EMbxzr_ox5RF3zQ/edit) discussed in this panel discussion: [https://www.youtube.com/watch?v=g5DGBWjiULQ&t=6496s](https://www.youtube.com/watch?v=g5DGBWjiULQ&t=6496s)) and also use inspiration from psychology, neuroscience and may touch upon philosophical issues such as ""what is the mind?""

If you are interested in joining please email me at [rinapy@gmail.com](mailto:rinapy@gmail.com) with subject ""How does the mind work"" so I have a sense of how many people will join.

Discussion: How does the mind work as an algorithm?

Wednesday, July 21 · 5:00 – 6:00pm (PST) ([Google-Calendar-link](https://calendar.google.com/event?action=TEMPLATE&tmeid=NzRxbWVhcjhpbnJwZnM0cWRmcm1wN290YmwgcmluYXB5QG0&tmsrc=rinapy%40gmail.com))

Google Meet joining info

Video call link: [https://meet.google.com/fdw-qmsa-ndx](https://meet.google.com/fdw-qmsa-ndx)

Thanks, Best,

Rina Panigrahy ([http://theory.stanford.edu/\~rinap/](http://theory.stanford.edu/~rinap/))",1626735611.0
1626789147.285477,t3_onbunj,,"[D] How did the do hyper-parameter tuning for large models like GPT-3, ERNIE etc, as they cost them millions for just training?",189,https://www.reddit.com/r/MachineLearning/comments/onbunj/d_how_did_the_do_hyperparameter_tuning_for_large/,IndieAIResearcher,r/MachineLearning,"Hi everyone,

I've worked on some deep learning, I've done some custom data training with hyperparameter tuning which taken some significant amount of time an money on cloud. I'm just wondering, how these people do hyperparameter tuning, architecture design etc, as training them costs millions. Or just it comes by experience?",1626692720.0
1626789147.299078,t3_onfb69,,[R] Deep Learning over the Internet: Training Language Models Collaboratively,86,https://www.reddit.com/r/MachineLearning/comments/onfb69/r_deep_learning_over_the_internet_training/,justheuristic,r/MachineLearning,"&#x200B;

[\[algorithm explained in a short video\]](https://reddit.com/link/onfb69/video/g9t39hklk6c71/player)

This is a story about 40-ish enthusiasts that trained a large transformer together over the internet. The blog post explains how a careful choice of training algorithm and model architecture can let you train a large BERT-like model on GPUs from across the world, despite the slow network and unreliable hardware.

This experiment is based on a recent paper by Hugging Face & Yandex about training on a swarm of heterogeneous unreliable GPUs. They use the hivemind library for parallelism and HF datasets for streaming the data.

Blog post: [https://huggingface.co/blog/collaborative-training](https://huggingface.co/blog/collaborative-training)

Hivemind: [https://github.com/learning-at-home/hivemind](https://github.com/learning-at-home/hivemind)",1626705442.0
1626789147.311777,t3_oo1on1,,[D] What resolution images do you usually use while training neural nets in general?,1,https://www.reddit.com/r/MachineLearning/comments/oo1on1/d_what_resolution_images_do_you_usually_use_while/,Alex55936,r/MachineLearning,"Does it matter much if use 64x64 images or 128x128 or even 256x256 images to train the neural network. How much the training accuracy is affected generally with lower v/s higher resolution images ?  

Also if anyone can tell what is the industry standard ?  And what is the standard for research applications if there is even one ? 

One obvious disadvantage of using very high res images is that the training takes more time and resources, are there are any other disadvantages ? And what about advantages ?


Edit: By industry standards I mean like the pretrained  models that are a available and widely used like the YOLO or many of the face detection models that have very high accuracy , etc .",1626786425.0
1626789147.322304,t3_oo0osb,,[D] Generalization through Memorization: Nearest Neighbor Language Models (Research Paper Walkthrough),1,https://www.reddit.com/r/MachineLearning/comments/oo0osb/d_generalization_through_memorization_nearest/,prakhar21,r/MachineLearning,"Bigger Models, Better Results ?? Always ?

This paper from Stanford University  and Facebook AI  proposes this very interesting idea of combining k-nearest neighbours with decently sized Language Model for handling factual inconsistency, generalisation and other existing issues with current text generation systems and surpassing large language models 🔥 🔥 

https://youtu.be/nJaekQb6DwU",1626782544.0
1626789147.332632,t3_onta3u,,"[D] Scalarization for Optimizing Multi-Objective ""Blackbox"" Functions (i.e. Gradient Free)",5,https://www.reddit.com/r/MachineLearning/comments/onta3u/d_scalarization_for_optimizing_multiobjective/,jj4646,r/MachineLearning,"Has anyone ever worked on problems in which you had to optimize multi-objective ""blackbox"" functions (i.e. functions where you can not take the derivatives, algorithms like gradient descent do not apply), e.g. using the genetic algorithm?

In the context of multi-objective optimization of non-blackbox functions, I read about some methods called ""scalarization"" which effectively transform multi-objective optimization problems into single-objective optimization problems.

For example: If you are trying to optimize three cost functions F1, F2, F3 ... you could combine these into a single problem using weighted coefficients, e.g. T = A * F1 + B* F2 + C *F3

A popular way to solve the above equation is to use methods like ""epsilon-constraint"": This is where you apply the desired constraints to F1, F2, F3 ... and then instruct the computer to loop through different values of A, B, C. Then, you see which combination of parameters (used in F1, F2, F3) result in the minimization of ""T"" - this is much easier to compare, since you can just rank all the candidate solutions. (source: https://www.youtube.com/watch?v=yc9NwvlpEpI)

This leads me to my question:

1) Do methods like ""epsilon constraint"" apply to ""Blackbox"" Functions? I.e. Can you use the ""epsilon constraint"" method along with the genetic algorithm?

2) Intuitively, when dealing with a multi-objective optimization problem: is there any way to deal with all the solutions along the ""Pareto Front""? Using the concept of the ""Pareto Front"" - suppose the optimization algorithm identifies a set of solutions that ""can not be made better in some criteria without worsening some other criteria"" ... how exactly can you rank and compare all the solutions along the Pareto Front? The concept of scalarization seemed useful, seeing how it converts a multi-objective optimization problem into a single-objective optimization problem, and therefore you can rank all the candidate solutions according to the ones that result in the minimum cost of the single objective .... but otherwise, how are you supposed to pick a solution among the set of solutions along the Pareto Front?

Thanks",1626749157.0
1626789147.352641,t3_onvrgb,,[D] Importance of Convergence Proof for Gradient Descent,2,https://www.reddit.com/r/MachineLearning/comments/onvrgb/d_importance_of_convergence_proof_for_gradient/,jj4646,r/MachineLearning,"https://imgur.com/a/r7jRcPJ

We all  probably know the importance of the gradient descent algorithm within the domain of machine learning (e.g. calculating the weights for neural networks) - but not all of have studied the inner details behind the gradient descent algorithm.

For instance, I was looking at this ""proof of convergence"" for the gradient descent algorithm over here: https://imgur.com/a/r7jRcPJ 

1) Just to clarify - in this case, does ""convergence"" mean it will necessarily reach some ""minimum"" (whether ""local"" or ""global"") point after k iterations? 

Or does it mean it mean that ""differences in the k-1 and k iteration will be negligible""? (I am not sure if this statement is characteristic of a ""minimum"" point? i.e the difference between the k-1 and k iteration is ONLY negligible when you reach some sort of minimum point?)

2) for a real-world dataset and choice of algorithm that uses gradient descent, is it ever possible to ""approximate"" the value of k in advance? could you ever (hypothetically) say that ""for this problem, I will approximately need to run gradient descent N number of times before I can reach an error of 0.2?""? (is this strong convergence or convergence in probability?)

3) are the performance results from an algorithm that uses gradient descent ever ""guaranteed within a certain error bound outside of the data it was exposed to""? or is this just wishful thinking?

4) https://imgur.com/a/r7jRcPJ in this picture, in the numerator on the term on the right hand side, do the ""two 2's stacked on each other"" refer to ""squared"" and ""l2 norm""?

if anyone has any other insights they would like to share on the ""importance of convergence for gradient descent"", please feel free to do so!

thanks",1626759124.0
1626789147.365377,t3_onax7l,,"Deep Learning should not be blindly applied to EVERY problem out there ""[Discussion]""",65,https://www.reddit.com/r/MachineLearning/comments/onax7l/deep_learning_should_not_be_blindly_applied_to/,erasperiko,r/MachineLearning,"Since the upsurge of Deep Learning (DL) from CNN in the image realm and from RNN for NLP, there is a clear trend towards this type of modeling technique. Mainly in context-specific areas such as finance, traffic, energy, etc, seems like every congress you attend for more than half of the publications are like this: ""So we have these datasets that have been feed to this exotic DL architecture. Our results excel the state of the art in a 0.1%. That is our contribution.""

I understand that it is an easy way to publish a paper as this kind of modeling technique is a hot topic right now. However, in my research context (which can be defined as 'traffic state prediction') can be disadvantageous. In a recent paper ([https://arxiv.org/abs/2012.02260](https://arxiv.org/abs/2012.02260)), we demonstrate that for a time series prediction approach, where data is self-descriptive (meaning that as a human being you can easily interpret the current values of the series) DL architectures do not overperform another less computational demandant algorithms such as the *all mighty* Random Forest.

The core idea behind this investigation is to shed light on an overlooked issue in this field: researchers apply modeling techniques without considering the endemic characteristics of their data collection:

* Is your data self-descriptive? 
* Is your data Euclidean?
* Are you going to benefit from the data fusion capabilities of DL?

I am only in my first research years but after reviewing lots of papers about this topic my concerns can be summarized as the above, and frankly, I do not like where this is going.",1626688474.0
1626789147.377206,t3_onz0k9,,A new-generation deep learning framework is launched[Project],0,https://www.reddit.com/r/MachineLearning/comments/onz0k9/a_newgeneration_deep_learning_framework_is/,Just0by,r/MachineLearning,"Hi, everyone.

This is the first time to introduce our project  [OneFlow](https://github.com/Oneflow-Inc/oneflow)  on Reddit, which is a performance-centered and open-source deep learning framework.

**OneFlow on GitHub**：[https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

OneFlow Benchmark：[https://github.com/Oneflow-Inc/OneFlow-Benchmark](https://github.com/Oneflow-Inc/OneFlow-Benchmark)

What is the big difference between OneFlow and TensorFlow or PyTorch? What challenges of DL framework OneFlow has solved for AI developers? To make you know well about OneFlow, Here are [some related articles](https://oneflow2020.medium.com) to explain its core techniques, including techniques of distributed training and the correct level of abstraction for distributed DL frameworks.

**Welcome to visit our project,** we would love to hear feedback and we wish you to use and contribute if you like our project.

Thank you!",1626775037.0
1626789147.392335,t3_onpn8k,,[R] Social Analysis Network analysis for Twitter in real time,4,https://www.reddit.com/r/MachineLearning/comments/onpn8k/r_social_analysis_network_analysis_for_twitter_in/,srpantano,r/MachineLearning,"I'm researching for my graduation work to analyze, in real time, how news affects the popularity of some on social media. For that, I would like to know if using Social Analysis Network is ideal?",1626736223.0
1626789147.404915,t3_onirgu,,[R] HTLM: Hyper-Text Pre-Training and Prompting of Language Models,8,https://www.reddit.com/r/MachineLearning/comments/onirgu/r_htlm_hypertext_pretraining_and_prompting_of/,ArmenAg,r/MachineLearning,"Arxiv: [https://arxiv.org/abs/2107.06955](https://arxiv.org/abs/2107.06955)

Twitter: [https://twitter.com/ArmenAgha/status/1415928833488785409](https://twitter.com/ArmenAgha/status/1415928833488785409)",1626715566.0
1626789147.414112,t3_onteod,,[D] Why does the genetic algorithm tend to NOT produce garbage results?,1,https://www.reddit.com/r/MachineLearning/comments/onteod/d_why_does_the_genetic_algorithm_tend_to_not/,jj4646,r/MachineLearning,"I spent a lot of time reading different articles online and watching lectures on youtube - and I could not seem to find any major theoretical results that ""guarantee"" some sort of performance for the genetic algorithm. The genetic algorithm seems to be a clever attempt to mimic the process of evolution and natural selection within the optimization framework - but it seems to work very well.

Does anyone know why this is? Has anyone ever attempted to understand from a mathematical perspective, why the genetic algorithm has been known to successfully explore complex spaces in real-world problems, and then return respectable results?",1626749644.0
1626789147.424052,t3_onk79q,,"[P] Pre-trained neural network for checking weapons (guns, knives) on image",4,https://www.reddit.com/r/MachineLearning/comments/onk79q/p_pretrained_neural_network_for_checking_weapons/,Affectionate_Teach23,r/MachineLearning,"Need a neural network for project to check if the weapon is on image or not. Nothing appropriate was found on Kaggle, GitHub, and Google. Do you know a pre-trained neural network to apply or where else can I look for it? Or it is better to train it by myself?",1626719733.0
1626789147.437634,t3_onlvhb,,[D] Black-box adversarial attacks and stochastic defensive methods,2,https://www.reddit.com/r/MachineLearning/comments/onlvhb/d_blackbox_adversarial_attacks_and_stochastic/,NongHyupJoy,r/MachineLearning,"I know that the paper 'On Evaluating Adversarial Robustness' recommends to do sanity check with black-box attacks to see if robustness comes from the gradient obfuscation. So I see many AA papers do additional experiment with black-box attacks.

However, I also am aware that the black-box attacks are not effective on the defensive methods using stochastic factors (injecting random noise to input image, weights or intermediate states ...), but I don't remember the source of it.

I see some papers using random factors as defense do not perform black-box attacks. For example, those two recent papers, [Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network](https://arxiv.org/abs/1810.01279) (Bayesian model with stochastic sampling) and [Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations](https://www.biorxiv.org/content/10.1101/2020.06.16.154542v1.full.pdf) (injecting noise to input image), they don't do any black-box attack. I am not fully confident of the reason why they didn't do black-box attack, but I guess the reason is that their model is utilizing randomness inside.

&#x200B;

I think doing black-box attack is necessary to make sure if it is not from gradient obfuscation even for defenses with randomness. Otherwise, how do one knows if the robustness is due to obfuscation or not?

I just want to know your thought on performing black-box attacks on defensive models with randomness. As those papers I posted did not do black-box attack, do you think it is not necessary to do black-box attack for stochastic defensive methods? (Maybe the reason for those works do not perform black-box attack is not what I expect.)

If you know any paper perform black-box attacks on stochastic defensive method, could you let me know? I want to know the proper way of doing black-box attack on stochastic defensive methods. ",1626724665.0
